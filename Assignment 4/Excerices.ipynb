{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Jexel\\Documents\\Yexel Files Documents\\TUE Complete\\WTB\\Jaar 2 AIESW\\Kwartiel 4\\5LSL0 Machine learning for signal processing\\Assignment\\5LSL0-1\\Assignment 4\n"
     ]
    }
   ],
   "source": [
    "# %% imports\n",
    "# libraries\n",
    "import torch\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "# local imports\n",
    "import MNIST_dataloader\n",
    "# import autoencoder_template\n",
    "from config_file import data_loc\n",
    "from matplotlib import pyplot as plt\n",
    "from MNIST_dataloader import create_dataloaders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1 - ISTA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### (a)[3 pt]Create a Python function that implements ISTA for MNIST denoising. \n",
    "Make sure the function takes as inputs: step size μ, shrinkage parameter λ, number of\n",
    "iteration K, and measurements (batch of MNIST images) y. It should output the\n",
    "final batch of reconstructions xK.\n",
    "\n",
    "hint: the images are normalized between -1 and 1, which means the background of the\n",
    "images is not at zero. Think about how to still aply ISTA correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "########## Define Paramters\n",
    "mu = 1e-4       # Step-size\n",
    "shrinkage = 0   # \n",
    "K = 10          # Amount of itereations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "### prepare the datasets\n",
    "# get dataloader\n",
    "batch_size = 64\n",
    "train_loader, test_loader, val_loader = create_dataloaders(data_loc, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% ISTA\n",
    "def softthreshold(x,shrinkage):\n",
    "    '''\n",
    "    Implement soft threshold:\n",
    "    F(x) = sign(x) * max(|x|)-lambda, 0_\n",
    "    Arguments:\n",
    "    ----------------------\n",
    "    x: data-set (default: train_dataset)??\n",
    "    shrinkage: float (default: --)\n",
    "    '''\n",
    "    new = torch.mul(torch.sign(x),torch.max(torch.abs(x)-shrinkage, 0)[0])\n",
    "    \n",
    "    return new\n",
    "\n",
    "def ISTA(mu,shrinkage,K,y):\n",
    "    '''\n",
    "    Iterative shrinkage and Thresholding Algorithm\n",
    "\n",
    "    Arguments:\n",
    "    --------------------\n",
    "    mu:     float (default: 0.5)\n",
    "        The stepsize\n",
    "\n",
    "    shrinkage:  float (default: 0.5)\n",
    "        The shrinking paramter\n",
    "    \n",
    "    K: int (default: 10)\n",
    "        The number of unfolding iterations\n",
    "    \n",
    "    y: ??? (default: ???)\n",
    "        The measurement image.\n",
    "\n",
    "    Returns:\n",
    "    --------------------\n",
    "    x: ??? (default: ???)\n",
    "        The denoised image    \n",
    "    '''\n",
    "    # initialize\n",
    "    ##### Using flattened features\n",
    "    # y2 = y.flatten()\n",
    "    # x = torch.zeros_like(y2)\n",
    "    # A = torch.eye(len(y2)) # length = WxH of image y\n",
    "\n",
    "    #### Using non-flattend features\n",
    "    y = y\n",
    "    x = torch.empty_like(y)\n",
    "    A = torch.eye(y)    \n",
    "    # use for-loop for K-number of iterations\n",
    "    for i in range(K):\n",
    "        ### write the for-loop\n",
    "        pass\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.2090,  0.5695,  0.6551,  ...,  0.2472, -0.9094,  0.2093],\n",
      "        [-0.5438, -0.5061,  0.5762,  ..., -0.9021,  0.0060, -0.6879],\n",
      "        [ 0.4019, -0.9449,  0.4926,  ...,  0.0738, -0.1771,  0.5592],\n",
      "        ...,\n",
      "        [-0.1933,  0.2455, -0.6462,  ..., -0.9546, -0.1896,  0.0710],\n",
      "        [-0.4428, -0.2875,  0.6662,  ..., -0.5267, -0.2497,  0.4986],\n",
      "        [ 0.0650, -0.2121, -0.1713,  ..., -0.6910, -0.3264,  0.8051]])\n"
     ]
    }
   ],
   "source": [
    "y = torch.Tensor(32, 32).uniform_(-1,1)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1024\n",
      "torch.Size([32, 32])\n",
      "tensor([[1., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 1., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 1.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 1., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 1., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.]])\n",
      "torch.Size([32, 32])\n"
     ]
    }
   ],
   "source": [
    "z = y.flatten()\n",
    "print(len(z))\n",
    "shap = y.shape\n",
    "print(shap)\n",
    "A = torch.eye(y.shape[0])\n",
    "print(A)\n",
    "x = torch.empty(shap)\n",
    "print(x.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x2150a9f4bb0>"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# init params\n",
    "mu = 0.5\n",
    "lamda = 0.5\n",
    "K = 1\n",
    "y = x_noisy_example[3,:,:,:]\n",
    "y = y\n",
    "x_test = torch.empty_like(y)\n",
    "x = torch.zeros_like(y)\n",
    "A = torch.eye(y.shape[0],y.shape[1])  \n",
    "\n",
    "# softthreshold(x,shrinkage)\n",
    "# we first initialize y->mu*A.T\n",
    "\n",
    "x_0 = y@(mu*A.T) # --> soft-treshold ---> I-mu*A.T*A\n",
    "x_0_soft = softthreshold(x_0,lamda)\n",
    "# x_k = x_0 + (x_0_soft - x_0_soft*A)\n",
    "for i in range(K):\n",
    "    # p_init = (A@x - y)\n",
    "    # x_k = x + mu*p_init\n",
    "    x_k = x_0 + (x_0_soft - x_0_soft*A)\n",
    "    x_0 = x_k\n",
    "    x_0_soft = softthreshold(x_0,lamda)\n",
    "\n",
    "plt.imshow(x_0_soft[0,:,:],cmap='gray')\n",
    "\n",
    "    \n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[-0.5303,  0.2261, -1.4305,  ..., -1.2996, -0.7251, -1.7388],\n",
       "          [-0.6452, -1.2132, -1.1929,  ..., -1.6255, -1.7102, -1.6422],\n",
       "          [-1.5097, -0.9324, -1.6783,  ..., -0.6178, -1.1962, -1.8434],\n",
       "          ...,\n",
       "          [-0.8682, -1.3313, -0.8090,  ..., -1.1923, -0.0395, -1.0516],\n",
       "          [-0.7573, -0.3469, -1.7947,  ...,  0.3228, -0.7713, -0.7367],\n",
       "          [-1.0862, -1.1235, -1.5547,  ..., -1.4084, -0.8460, -0.9280]]],\n",
       "\n",
       "\n",
       "        [[[-1.6549, -0.6092, -1.2485,  ..., -0.5038, -1.2268, -1.3574],\n",
       "          [-1.0344, -1.6878, -1.2185,  ..., -0.2723, -0.2964, -0.1505],\n",
       "          [-1.2929, -2.0204, -1.1897,  ..., -0.9976, -1.0987, -0.9843],\n",
       "          ...,\n",
       "          [-0.9823, -1.1581, -1.7435,  ..., -0.7535, -0.2427, -1.5870],\n",
       "          [-1.0101, -1.1014, -1.0749,  ..., -0.6235, -1.7668, -1.2693],\n",
       "          [-0.6484, -1.1633, -0.1700,  ..., -0.5256, -1.1546, -0.9140]]],\n",
       "\n",
       "\n",
       "        [[[-0.8795, -2.0543, -1.0930,  ..., -1.0731, -0.4957, -0.5783],\n",
       "          [-1.5600, -0.8441, -1.9451,  ..., -0.5753, -0.8237, -2.3348],\n",
       "          [-0.6850, -1.5980, -0.6583,  ..., -0.6064, -0.8475,  0.0452],\n",
       "          ...,\n",
       "          [-1.6726, -1.2049, -1.1250,  ..., -0.7334, -1.2620, -0.7077],\n",
       "          [-0.6516, -1.3921, -0.7953,  ..., -1.0503, -1.1113, -0.6040],\n",
       "          [-0.9119, -1.4344, -0.8307,  ..., -0.0471, -1.1364, -0.9131]]],\n",
       "\n",
       "\n",
       "        ...,\n",
       "\n",
       "\n",
       "        [[[-1.0907, -1.4720, -0.6037,  ..., -0.6015, -1.3401, -2.3180],\n",
       "          [-0.8166, -0.9107, -1.1935,  ..., -1.5733, -0.6244, -0.6482],\n",
       "          [-1.8768, -0.8628, -0.5129,  ..., -1.2526, -0.5402, -0.8398],\n",
       "          ...,\n",
       "          [-2.1776, -0.8775, -1.0658,  ..., -1.3985, -2.0794, -1.9882],\n",
       "          [-1.4385, -0.5887, -0.8857,  ..., -1.3963, -1.2879, -0.3890],\n",
       "          [-0.7998, -1.0618, -1.5405,  ..., -1.1555, -2.0496, -0.4603]]],\n",
       "\n",
       "\n",
       "        [[[-0.9072, -1.3743, -1.3738,  ..., -1.7121, -0.2953, -1.4290],\n",
       "          [-0.9313, -1.1360, -1.0494,  ..., -1.3600, -0.4543, -0.2114],\n",
       "          [-1.6696, -0.3046, -1.0467,  ..., -0.7027, -1.3385, -1.0686],\n",
       "          ...,\n",
       "          [-1.2983, -1.2907, -0.8449,  ..., -1.1608, -0.8438, -0.5155],\n",
       "          [-1.3751, -2.1659, -2.1023,  ..., -0.3815, -0.4133, -1.2263],\n",
       "          [-0.4802, -1.9736, -0.7885,  ..., -0.5292, -1.1834, -1.4708]]],\n",
       "\n",
       "\n",
       "        [[[-1.1930, -0.9167, -0.2333,  ..., -0.4438, -0.1751, -0.9549],\n",
       "          [-2.4184, -1.4828, -0.6458,  ..., -1.2205, -0.8968, -1.1098],\n",
       "          [-1.1237, -1.1447, -2.0913,  ..., -0.9329, -1.4570, -1.0513],\n",
       "          ...,\n",
       "          [-0.8362, -0.9386, -1.4907,  ..., -1.0069, -0.8656, -1.5303],\n",
       "          [-0.6196, -1.4724, -1.7079,  ..., -0.5676,  0.1979, -0.8851],\n",
       "          [-0.9600, -1.3293, -0.7542,  ..., -0.1026, -1.0928, -1.5233]]]])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_noisy_example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0.])\n"
     ]
    }
   ],
   "source": [
    "new = torch.max(torch.abs(x)-shrinkage, 0)\n",
    "print(new[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "torch.Size([32, 32])\n",
      "tensor([0.7910, 1.5695, 1.6551,  ..., 0.3090, 0.6736, 1.8051])\n"
     ]
    }
   ],
   "source": [
    "print(x)\n",
    "print(x_0.size())\n",
    "print(y.flatten()+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0 2]\n",
      "[[ 1  6  5]\n",
      " [ 3  4  8]\n",
      " [ 2 12  3]]\n",
      "[[  0  -6  -3]\n",
      " [ -2  -4  -6]\n",
      " [ -1 -12  -1]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    " \n",
    "# input two matrices\n",
    "mat1 = np.array(([1, 6, 5],[3 ,4, 8],[2, 12, 3]))\n",
    "mat2 = np.array(([3, 4, 6],[5, 6, 7],[6,56, 7]))\n",
    "xx = np.array(([1, 0, 2]))\n",
    "# This will return matrix product of two array\n",
    "res = mat1 @ mat2\n",
    " \n",
    "# print resulted matrix\n",
    "print(xx)\n",
    "print(mat1)\n",
    "print(xx - mat1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader, val_loader, test_loader = create_dataloaders(data_loc,batch_size)\n",
    "x_clean_train = train_loader.dataset.Clean_Images\n",
    "x_noisy_train = train_loader.dataset.Noisy_Images\n",
    "labels_train  = train_loader.dataset.Labels\n",
    "x_clean_test  = test_loader.dataset.Clean_Images\n",
    "x_noisy_test  = test_loader.dataset.Noisy_Images\n",
    "labels_test   = test_loader.dataset.Labels\n",
    "\n",
    "# use these 10 examples as representations for all digits\n",
    "x_clean_example = x_clean_test[0:10,:,:,:]\n",
    "x_noisy_example = x_noisy_test[0:10,:,:,:]\n",
    "labels_example = labels_test[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([], [])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAOsAAADrCAYAAACICmHVAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAAsTAAALEwEAmpwYAAATvUlEQVR4nO2d3VPW5fbG1wOCyAMKCkqIL+ArGC+KiGYpGsyolDPaQWMHTVl50P9QM3XWOP0FddJB2lSTk+OkpaZNYKnga+YryJuKCAIiyqv8jvbvYM99XXt/mb2nvfa+Pof31Xqe7/N9nouv3etea8UmJiZMCPGfT8JffQFCiH8OmVUIJ8isQjhBZhXCCTKrEE6QWYVwwpQo/3EsFptISAj7Ox6Pw7jk5ORI62Zmg4ODUEtJSYHa2NgY1MbHx4PriYmJMCYWi0GNpb2mTMG3dnR0FGpTp04Nrg8NDcEY9LnM+PWzOPTdsM/MPte0adOgxhgeHv6Xvt7IyAjU2GdD34sZ/q0yT6B7NTg4aMPDw8EvLZJZExIS4AVUVlbCuHnz5gXX586dC2MaGxuhtnjxYqj19vZG1jIyMmAM+4PCDJSVlQW1zs5OqKHPdvXqVRjz+PFjqCUlJUGtv78faui7YYbs6uqCWnFxMdTYH43bt28H10tKSmAM+4Pd0dExqevIz8+H2tmzZ4Pra9asgTF37twJrh87dgzG6J/BQjhBZhXCCTKrEE6QWYVwQqQNpszMTHv11VeDWk5ODoz7448/guvsf/bZ/9CzncBr165BraysLLiOrs/MrKCgAGpNTU1QW7t2LdRu3rwJNbTbzjal2traoFZTUwO148ePQw3d482bN8OYo0ePQu3Ro0dQY9c/f/784Pr3338PY3bt2gU1xowZM6DGdpHnzJkTXGcbf0+ePAmuP3v2DMboySqEE2RWIZwgswrhBJlVCCfIrEI4QWYVwgmxKD2YsrKyJrZv3x7U2Db16tWrg+tsyx5tbZuZPX36FGps+x0dxmZpEXYWlhUbTJ8+HWq5ublQQ2dh2ZnnWbNmQY2ludghf5RqYa/34MEDqGVmZkKNHXhfuXJlcB2drTXjqTH2mdn5a3a2GaUEWbrn7t27wfWDBw9ad3d38CL1ZBXCCTKrEE6QWYVwgswqhBNkViGcEOkg/8TEBKzCZ7uVaGfx4sWLMGbJkiVQe/jwIdTYbiV6TXbtLS0tUJs5cybU2C57e3s71EpLS4Prra2tMIbtZqMuHWZ459kMFzCcO3cOxpSXl0Ptp59+ghrbzUa7pqwLA9tdZoUZrBUP28Gvr68Prq9btw7GoJ1z1uVCT1YhnCCzCuEEmVUIJ8isQjhBZhXCCTKrEE6IdJB/1qxZE7W1tUGNNcpGaYfCwkIYc+/ePaihnjdmZnv37oXaBx98EFxnBQXs/rA00YkTJ6C2atUqqKFiA5QeMDPbs2cP1A4ePAg1ltZB6RR27wcGBqDGDvmzz7Zp06bgOuvpxJrHswIAVgSCJgOY4WbvrGk40o4fP269vb06yC+EZ2RWIZwgswrhBJlVCCfIrEI4QWYVwgmRqm6Sk5Phtnh3dzeMQ/2ImpubYQzb6mdVK0uXLoXa+fPng+tFRUWRY8zM8vLyoMZ6MKHKGjOzS5cuBddZtchHH30ENZaOQKM6zPDnZjNpt27dCrW0tLRJxSFYuu3KlStQQ+NfzMyys7Oh9t1330ENpeIaGhpgzLvvvhtcZ3OJ9WQVwgkyqxBOkFmFcILMKoQTZFYhnCCzCuGESFU38Xh84vnnnw9qFRUVMA5Vaty6dQvGsAnQPT09UGMVLahB240bN2AMGhdiZnb//n2osSZsrFEZGjPB0kvsO2T3cfny5VBDk8VTUlJgDKviYak9NF7FDH/XbBxHX18f1NjoFTayJT09HWqnT58OrpeUlMCYM2fOBNebm5vt6dOnqroRwjMyqxBOkFmFcILMKoQTZFYhnCCzCuGESFU3mZmZtnPnzqB26tQp/CZghgibWcOmirNqF7b9jq6DNT5j1TOoQsbMbNGiRVBj14/m1rA0EUtHsOZhqampUENzgdhcnS1btkzqvRgo/cF+b6zCh1VsHTlyBGpJSUlQQ9PU+/v7YQyreIIxkSOEEH8JMqsQTpBZhXCCzCqEE2RWIZwQaTd4dHQUTqKeP38+jEOjJBYuXAhj2CiG0dFRqLEJ2yhu165dMIYVDbDD9U1NTVBjO8xoN5vtLrND8uwg//Xr16FWXV0dXD906BCMYYfd0Y6pGR4ZYoZ3disrK2EMG3XBds5feuklqKGD92b4+2QFG4sXLw6ud3R0wBg9WYVwgswqhBNkViGcILMK4QSZVQgnyKxCOCFS6mZoaMhu3rwZ1FgPpqqqquB6cnIyjElMTIQaO+Sfk5MDNdSfiW2xs+tg6SV2UDsej0MNTfRm18F6KbGUGjt4j+4JGvtgZnby5Emood5dZrxnEiq+YGk/NnqlsLAQaqxIgfWeQj2k2NT5/Pz84DorUNCTVQgnyKxCOEFmFcIJMqsQTpBZhXCCzCqEEyKNz8jKyppA4ySuXr0K41CPI5ZyYNOr2TRvNrLg6NGjwfV33nkHxnz22WdQY2mi8fFxqLGqG5TyQVUwZji9YWY2MjICNVaBgtJqFy5cgDFs6jwbJ8JSYKgyaNu2bTDmhRdemNR7zZw5E2rot2OGK5HY7wNNkD9x4oT19vZqfIYQnpFZhXCCzCqEE2RWIZwgswrhBJlVCCdEqrqZNm2aFRcXBzVWsYC2qRnZ2dlQY2kdVkGDJnMfO3YMxrBql8ePH0ONTeYeGxuDWlZWVnC9tbUVxrz55ptQYw3k2HXU19cH11lzM5beWLt2LdR++OEHqK1YsSK4ziq27ty5AzWWUmOjV1hTOjRq5Oeff4YxqOEbq9bSk1UIJ8isQjhBZhXCCTKrEE6QWYVwgswqhBMipW76+/vt8OHDQY1N5l62bFlwnU0+Z+kZlD4y41v6qNqFbZezFAybf7JgwQKooRSSGW7qVl5eDmNYymHWrFlQu3XrFtQQ165dgxr6ns14muu1116DGqoo6urqgjGsKisjI2NS2pw5c6CGfj9sPhHSWGpMT1YhnCCzCuEEmVUIJ8isQjhBZhXCCTKrEE6IlLpJSkqCW9jr16+HcWgGCtsOZykH1iCMxR05ciS4vmHDBhgzOjoKtZdffhlqrFkWa2JWU1MTXGeNyhis4olVKNXV1QXX33//fRjz5ZdfQm3nzp1QO3v2LNTQjJzFixfDmNdffx1q6HOZGZzjZMYraFDKqqioCMZEaVT4N/RkFcIJMqsQTpBZhXCCzCqEE2RWIZzwL+vBxHbS0CHusrIyGMMOwn/11VdQYzu06PB0eno6jGlpaYEaO1zPJnOjqddm+D42NTXBmFgsOG3BzMyGh4ehxl7zxRdfDK6zXendu3dDbd++fVB75ZVXoIZ2WlmPrm+++QZqrBBhcHAQamzsxi+//BJcZ5kJdGCfjTTRk1UIJ8isQjhBZhXCCTKrEE6QWYVwgswqhBMipW5GRkasvb09qD169AjGoQPNaWlpUd7+/2FFA6mpqVBLSkoKrrOeSKxPFDuMzcZWsAPeaEs/NzcXxjQ0NEAtJSUFamzyPBqHgkZFmPExJOhA/j8C9cBi95f9Po4fPw41dj/Yb2T27NnBdVY0gKbEs3EterIK4QSZVQgnyKxCOEFmFcIJMqsQTpBZhXBCLEovmOzs7IkdO3YEtbt378I41HOov78fxqBRF2Y8ncJGJ6A0RlVVFYxB6R4znsZgIzl6enqghiphDh06BGNmzpwJNVb5wdI606ZNC66za2fVRM+ePYPa5s2boYbGZNTW1sIYVhnEprMzL7Bp6ug+stRkY2NjcP3ChQs2MDAQLKPSk1UIJ8isQjhBZhXCCTKrEE6QWYVwgswqhBMiVd0MDQ3Bhl5snAHa7p8/fz6MYekZVgHBGk51dHQE17OysmDM2NgY1Fj1DJsqzt7vwIEDwXV2ry5fvgw1NmqEpdtQJQlrBMfuFauEefDgQeTX/PTTT2HM77//DrXS0tJJxZWUlEANTZ5PTk6GMXl5ecH1K1euwBg9WYVwgswqhBNkViGcILMK4QSZVQgnyKxCOCFS6iYej9vq1auD2pkzZ2Acmj9z/vx5GLNq1Sqo/fnnn1BjVFRUBNdZM6/e3l6osTQGa8z122+/QQ1V8rAqHtasDqVgzHhVCPpsrHqGpbLYe7G5NSgVx9IsLBV07tw5qLG0DprXxDh8+DDU4vF4cF2zboT4L0BmFcIJMqsQTpBZhXCCzCqEEyKPz2hrawtqOTk5MA4d/kevZcYPTrPp1e+99x7U0GgK1mcJjW8wM/vkk0+gxnYkh4aGoIZ21SsrK2EMm2De3d0NNdYzCY13KCgogDHoQLsZ7wV1+vRpqNXX1wfX2TiRdevWQa2vrw9q9+/fhxrbsUaFGayw4bnnnguus9+NnqxCOEFmFcIJMqsQTpBZhXCCzCqEE2RWIZwQaXxGamrqBDpoXlNTA+PQljhLYbCRECxNxHoVbdq0KbjOxngMDAxAjR0m37dvH9RY4QA6eI9GkJjxQ/6s3xMqyjAzKy8vD67fvn17Utdx5MgRqDU3N0MNTTh/6623YAwrXti/fz/UJnuQPyMjI7jOvNXe3h5cr6urs76+Po3PEMIzMqsQTpBZhXCCzCqEE2RWIZwgswrhhEhVNykpKVZYWBjUOjs7YRzq58PGN7CUCUsRoIndZniKNrsONumb9YJir1ldXQ011OOIVSFNduwDq1xBfaJYVciKFSugxvptDQ8PQ23btm3BddbfiI1XYVVUrEoGVY6ZmVVVVQXXjx07BmNWrlwZXGfjTvRkFcIJMqsQTpBZhXCCzCqEE2RWIZwgswrhhEipm4SEBEtNTQ1qrBLm4sWLwXVUeWBmNj4+DjU2RXvGjBlQQxU5DQ0NMIaNwVi2bBnUNm7cCDVWbYTGhrDKoK1bt0KNpTHQd2mGUyZXr16FMXv37oUaSyGh34cZrthCDcfMzObOnQs1luZik8on07AOVXmZ4ZEnsViw4MbM9GQVwg0yqxBOkFmFcILMKoQTZFYhnCCzCuGESKmbWCwGt7dbWlpgHJoTwlIHt27dghqqcmDvZYav8c6dO5N6LzYbBVVVmPE0BqoMQg3MzHilRkdHB9ROnToFNfQ9syokNrNm+fLlUGONxVCai91fNC/IjDdTY43sGJcvXw6usyZr27dvD66jBnFmerIK4QaZVQgnyKxCOEFmFcIJMqsQToi0Gzw2NgZ3KxmoZxLbuWUHmtnOMzvIjw6hFxUVwRhWoMAO8qelpUFt+vTpUEM7o6zYgI0uYbuLrG8WGl/CYth080uXLkGNFTagnW52+J+NDGG9vdra2qDGemqh3f3r16/DGHQfR0dHYYyerEI4QWYVwgkyqxBOkFmFcILMKoQTZFYhnBApdROPx23t2rVBjY1H6OvrC64/efIExhQUFECNHdRGvW3MzPbs2RNcRwexzcyePn0KNZaCQdOwzczq6+uhhvoHsRRMSkoK1FifqzVr1kDtxo0bwXU2ngSN/jDjYzdYr6IrV64E19PT02EM+w2wFAwrzGDXiMaGsCIK9Jtjvzc9WYVwgswqhBNkViGcILMK4QSZVQgnyKxCOCFS6mZkZASmAtj0apTuYWmAuro6qE2dOhVqrNoFVWqUlpbCGDQB3Mxszpw5UEPpKjOz5uZmqKFKDdbDaP/+/VArKyuD2mQmc//4448wpri4GGqseomN5ECpLJaSYr/F1atXQ431gmptbYUaStGw3+nIyEhwXeMzhPgvQGYVwgkyqxBOkFmFcILMKoQTZFYhnBBj29V/TzwenygsLEQajEMVKCxlwiogrl27BrWPP/4YagcOHAiusynaiYmJUGNjN1iVCWsU9+uvvwbXWYUPqvow443W2LgI1DyMTRVn6RTWqIx9NlSZxaqyWLqKNdvr7u6G2sOHD6GWmZkZXGdjUlBq74svvrDOzs5g/kZPViGcILMK4QSZVQgnyKxCOEFmFcIJMqsQTohUdTM+Pm79/f1BraKiAsahtM7XX38NY6qrq6G2aNEiqH344YdQQw29WBXMxo0boZaUlAS1sbExqLFUBUpxsAollkJav3491FjDOlRBw+4VS4GxGUSssRj63Ow60JweM97Yb926dVC7efNmZI2lid54443gOpo4b6YnqxBukFmFcILMKoQTZFYhnCCzCuEEmVUIJ0SedYO2t9lI9t27dwfXWfUMq3Zhs11YdUR+fn5wvba2FsawxmdNTU1QY42v2CyWDRs2BNd7enpgzJIlS6DGrpGlkBDsfrBKo7fffhtqhw4dghr7rhFsXszChQuhxlJI5eXlUENpuqGhIRjT2NgYXGfpND1ZhXCCzCqEE2RWIZwgswrhBJlVCCdE2g2eMmWKZWVlBTU26fvcuXPB9YQE/LeCTdFm/Xxyc3OhhnoOjY6Owhi2G3nv3j2osTEe7HOjHlcnT56EMawgYsuWLVBjfbPQxPF58+bBGLaD/+2330KN7dCi62C7puwgPxpbYWa2fft2qH3++edQ27FjR3Ad9dMyM0tNTQ2us9+inqxCOEFmFcIJMqsQTpBZhXCCzCqEE2RWIZwQKXWTlJQEp33X19fDONRvhh1oHxwchFpXVxfU0MRuM3zAmx1Anz17NtTy8vKgxkZJsAPeR48eDa6zLX02YXsy07fNcHEAmwTPXm/p0qVQQ+kZM1wQUVlZCWNYuo0VWJw9exZqCxYsgBpKTbLriDK25m/oySqEE2RWIZwgswrhBJlVCCfIrEI4QWYVwgmRJp/HYrEHZtb677scIf7nWTAxMZEdEiKZVQjx16F/BgvhBJlVCCfIrEI4QWYVwgkyqxBOkFmFcILMKoQTZFYhnCCzCuGE/wNkKqGw3oiwQgAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "reconses = torch.zeros((10,1,x_noisy_example.shape[-1],x_noisy_example.shape[-1]))\n",
    "test = x_noisy_example[1,0,:,:]\n",
    "plt.imshow(x_noisy_example[3,0,:,:],cmap='gray')\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### (b) [2 pt] Use your ISTA algorithm on 10 example images. \n",
    "Show them in a figure consisting of 10 collumns (1 per digit) and 3 rows. Row 1 should contain the noisy\n",
    "measurement, row 2 the reconstruction, and row 3 the actual ground truth target.\n",
    "You will have to play with the values for μ, λ, and K. Explain what you see."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### (c) [1 pt] To get a numerical estimate for the performance of ISTA, run it on the entire test set and report the resulting mean squared error (mse)."
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "0cebc76ff3e953d686a385ef65c3cec7b5011a0054b629434b2c338049b9ef59"
  },
  "kernelspec": {
   "display_name": "Python 3.8.13 ('PGPUC')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
