{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% imports\n",
    "# libraries\n",
    "import torch\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "# local imports\n",
    "import MNIST_dataloader\n",
    "# import autoencoder_template\n",
    "from config_file import data_loc\n",
    "from matplotlib import pyplot as plt\n",
    "from MNIST_dataloader import create_dataloaders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1 - ISTA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### (a)[3 pt]Create a Python function that implements ISTA for MNIST denoising. \n",
    "Make sure the function takes as inputs: step size μ, shrinkage parameter λ, number of\n",
    "iteration K, and measurements (batch of MNIST images) y. It should output the\n",
    "final batch of reconstructions xK.\n",
    "\n",
    "hint: the images are normalized between -1 and 1, which means the background of the\n",
    "images is not at zero. Think about how to still aply ISTA correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "########## Define Paramters\n",
    "mu = 1e-4       # Step-size\n",
    "shrinkage = 0   # \n",
    "K = 10          # Amount of itereations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "### prepare the datasets\n",
    "# get dataloader\n",
    "batch_size = 64\n",
    "train_loader, test_loader, val_loader = create_dataloaders(data_loc, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% ISTA\n",
    "def softthreshold(x,shrinkage):\n",
    "    '''\n",
    "    Implement soft threshold:\n",
    "    F(x) = sign(x) * max(|x|)-lambda, 0_\n",
    "    Arguments:\n",
    "    ----------------------\n",
    "    x: data-set (default: train_dataset)??\n",
    "    shrinkage: float (default: --)\n",
    "    '''\n",
    "    new = torch.mul(torch.sign(x),torch.max(torch.abs(x)-shrinkage, 0))\n",
    "    \n",
    "    return new\n",
    "\n",
    "def ISTA(mu,shrinkage,K,y):\n",
    "    '''\n",
    "    Iterative shrinkage and Thresholding Algorithm\n",
    "\n",
    "    Arguments:\n",
    "    --------------------\n",
    "    mu:     float (default: 0.5)\n",
    "        The stepsize\n",
    "\n",
    "    shrinkage:  float (default: 0.5)\n",
    "        The shrinking paramter\n",
    "    \n",
    "    K: int (default: 10)\n",
    "        The number of unfolding iterations\n",
    "    \n",
    "    y: ??? (default: ???)\n",
    "        The measurement image.\n",
    "\n",
    "    Returns:\n",
    "    --------------------\n",
    "    x: ??? (default: ???)\n",
    "        The denoised image    \n",
    "    '''\n",
    "    # initialize\n",
    "    ##### Using flattened features\n",
    "    # y2 = y.flatten()\n",
    "    # x = torch.zeros_like(y2)\n",
    "    # A = torch.eye(len(y2)) # length = WxH of image y\n",
    "\n",
    "    #### Using non-flattend features\n",
    "    y = y\n",
    "    x = torch.empty_like(y)\n",
    "    A = torch.eye(y)    \n",
    "    # use for-loop for K-number of iterations\n",
    "    for i in range(K):\n",
    "        ### write the for-loop\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 87.5784, 137.6103, 156.0368,  ..., 140.0040,  80.8602,  80.3002],\n",
      "        [ 24.5583,  24.2110,  34.7155,  ...,   9.5193, 219.8152, 151.1400],\n",
      "        [ 92.2112,  58.0858, 131.6390,  ..., 192.5061,  70.1760, 183.0031],\n",
      "        ...,\n",
      "        [  8.2174,  85.0267, 218.4816,  ...,  54.6934, 183.9227,  99.5359],\n",
      "        [185.3454,  90.8415, 145.4967,  ..., 179.3370, 221.4976,  23.4768],\n",
      "        [122.5168,  86.3312, 109.1421,  ...,  54.5471,  55.4464,  69.9607]])\n"
     ]
    }
   ],
   "source": [
    "y = torch.Tensor(32, 32).uniform_(0, 225)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1024\n",
      "torch.Size([32, 32])\n",
      "tensor([[1., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 1., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 1.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 1., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 1., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.]])\n",
      "torch.Size([32, 32])\n"
     ]
    }
   ],
   "source": [
    "z = y.flatten()\n",
    "print(len(z))\n",
    "shap = y.shape\n",
    "print(shap)\n",
    "A = torch.eye(y.shape[0])\n",
    "print(A)\n",
    "x = torch.empty(shap)\n",
    "print(x.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-7.5739e-31,  6.8664e-43, -7.5737e-31,  ...,  6.8664e-43,\n",
      "         -3.9224e+31,  6.8664e-43],\n",
      "        [-3.9223e+31,  6.8664e-43, -3.9223e+31,  ...,  6.8664e-43,\n",
      "         -7.4770e-31,  6.8664e-43],\n",
      "        [-7.4778e-31,  6.8664e-43, -7.4783e-31,  ...,  6.8664e-43,\n",
      "         -7.4776e-31,  6.8664e-43],\n",
      "        ...,\n",
      "        [-7.3651e-31,  6.8664e-43, -7.3659e-31,  ...,  6.8664e-43,\n",
      "         -7.3664e-31,  6.8664e-43],\n",
      "        [-7.3658e-31,  6.8664e-43, -7.3648e-31,  ...,  6.8664e-43,\n",
      "         -1.0468e+13,  6.8664e-43],\n",
      "        [-1.0508e+13,  6.8664e-43, -6.4208e+11,  ...,  6.8664e-43,\n",
      "         -1.0495e+13,  6.8664e-43]])\n"
     ]
    }
   ],
   "source": [
    "# init params\n",
    "mu = 0.5\n",
    "lamda = 0.5\n",
    "K = 10\n",
    "\n",
    "y = y\n",
    "x = torch.empty_like(y)\n",
    "A = torch.eye(y.shape[0],y.shape[1])  \n",
    "\n",
    "for i in range(K):\n",
    "    p_init = (A@x - y)\n",
    "    x_k = x + mu*p_init\n",
    "    \n",
    "    \n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0 2]\n",
      "[[ 1  6  5]\n",
      " [ 3  4  8]\n",
      " [ 2 12  3]]\n",
      "[[  0  -6  -3]\n",
      " [ -2  -4  -6]\n",
      " [ -1 -12  -1]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    " \n",
    "# input two matrices\n",
    "mat1 = np.array(([1, 6, 5],[3 ,4, 8],[2, 12, 3]))\n",
    "mat2 = np.array(([3, 4, 6],[5, 6, 7],[6,56, 7]))\n",
    "xx = np.array(([1, 0, 2]))\n",
    "# This will return matrix product of two array\n",
    "res = mat1 @ mat2\n",
    " \n",
    "# print resulted matrix\n",
    "print(xx)\n",
    "print(mat1)\n",
    "print(xx - mat1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### (b) [2 pt] Use your ISTA algorithm on 10 example images. \n",
    "Show them in a figure consisting of 10 collumns (1 per digit) and 3 rows. Row 1 should contain the noisy\n",
    "measurement, row 2 the reconstruction, and row 3 the actual ground truth target.\n",
    "You will have to play with the values for μ, λ, and K. Explain what you see."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### (c) [1 pt] To get a numerical estimate for the performance of ISTA, run it on the entire test set and report the resulting mean squared error (mse)."
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "0cebc76ff3e953d686a385ef65c3cec7b5011a0054b629434b2c338049b9ef59"
  },
  "kernelspec": {
   "display_name": "Python 3.8.13 ('PGPUC')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
